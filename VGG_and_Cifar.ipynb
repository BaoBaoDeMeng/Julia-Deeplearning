{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG and Cifar\n",
    "\n",
    "在该实现中您可以看到如下功能：\n",
    "1. 设置训练过程中的参数\n",
    "2. 读取 Cifar10 数据集并创建训练集和测试集\n",
    "3. 使用图像增广\n",
    "4. 使用预训练的 VGG19 模型\n",
    "5. 训练、测试和保存模型\n",
    "\n",
    "In this template you can finish the following functions:\n",
    "1. Set the parameters during training\n",
    "2. Read Cifar10 data set and create training set and test set\n",
    "3. Use image augmentation\n",
    "4. Use the pre-trained VGG19 model\n",
    "5. Train, test and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Metalhead, Statistics\n",
    "using Flux: onehotbatch, onecold, logitcrossentropy, throttle, flatten\n",
    "using Metalhead: trainimgs\n",
    "using Parameters: @with_kw\n",
    "using Images: channelview\n",
    "using Statistics: mean\n",
    "using Base.Iterators: partition\n",
    "using CUDAapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training on GPU-3\n",
      "└ @ Main In[2]:7\n"
     ]
    }
   ],
   "source": [
    "using CUDAapi, CUDAdrv, CUDAnative\n",
    "gpu_id = 3  ## set < 0 for no cuda, >= 0 for using a specific device (if available)\n",
    "\n",
    "if has_cuda_gpu() && gpu_id >=0\n",
    "    device!(gpu_id)\n",
    "    device = Flux.gpu\n",
    "    @info \"Training on GPU-$(gpu_id)\"\n",
    "else\n",
    "    device = Flux.cpu\n",
    "    @info \"Training on CPU\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了便于调整参数和记录试验结果，我们需要使用 parameters 将参数记录和封装。\n",
    "\n",
    "In order to easily adjust the parameters and record the test results, we need to use parameters to record and encapsulate the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Parameters: @with_kw\n",
    "@with_kw mutable struct Args\n",
    "    batchsize::Int = 128\n",
    "    throttle::Int = 10\n",
    "    lr::Float64 = 3e-4\n",
    "    epochs::Int = 10\n",
    "    splitr_::Float64 = 0.1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参照pytorch实现图像增广的预处理过程。\n",
    "\n",
    "Refer to pytorch to realize the preprocessing process of image augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preprocess (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without augmentation\n",
    "function preprocess(X)\n",
    "    Float32.(permutedims(channelview(X), (2, 3, 1)))\n",
    "end\n",
    "\n",
    "# # with augmentation\n",
    "# function resize_smallest_dimension(im, len)\n",
    "#   reduction_factor = len/minimum(size(im)[1:2])\n",
    "#   new_size = size(im)\n",
    "#   new_size = (\n",
    "#       round(Int, size(im,1)*reduction_factor),\n",
    "#       round(Int, size(im,2)*reduction_factor),\n",
    "#   )\n",
    "#   if reduction_factor < 1.0\n",
    "#     # Images.jl's imresize() needs to first lowpass the image, it won't do it for us\n",
    "#     im = imfilter(im, KernelFactors.gaussian(0.75/reduction_factor), Inner())\n",
    "#   end\n",
    "#   return imresize(im, new_size)\n",
    "# end\n",
    "\n",
    "# # Take the len-by-len square of pixels at the center of image `im`\n",
    "# function center_crop(im, len)\n",
    "#   l2 = div(len,2)\n",
    "#   adjust = len % 2 == 0 ? 1 : 0\n",
    "#   return im[div(end,2)-l2:div(end,2)+l2-adjust,div(end,2)-l2:div(end,2)+l2-adjust]\n",
    "# end\n",
    "\n",
    "# function preprocess(im)\n",
    "#   # Resize such that smallest edge is 256 pixels long\n",
    "#   im = resize_smallest_dimension(im, 256)\n",
    "\n",
    "#   # Center-crop to 224x224\n",
    "#   im = center_crop(im, 224)\n",
    "\n",
    "#   # Convert to channel view and normalize (these coefficients taken\n",
    "#   # from PyTorch's ImageNet normalization code)\n",
    "#   μ = [0.485, 0.456, 0.406]\n",
    "#   # the sigma numbers are suspect: they cause the image to go outside of 0..1\n",
    "#   # 1/0.225 = 4.4 effective scale\n",
    "#   σ = [0.229, 0.224, 0.225]\n",
    "#   #im = (channelview(im) .- μ)./σ\n",
    "#   im = (channelview(im) .- μ)\n",
    "\n",
    "#   # Convert from CHW (Image.jl's channel ordering) to WHCN (Flux.jl's ordering)\n",
    "#   # and enforce Float32, as that seems important to Flux\n",
    "#   # result is (224, 224, 3, 1)\n",
    "#   #return Float32.(permutedims(im, (3, 2, 1))[:,:,:,:].*255)  # why\n",
    "#   return Float32.(permutedims(im, (3, 2, 1))[:,:,:,:])\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建训练集合、验证集合和测试集合。\n",
    "\n",
    "Build training set, validation set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_test_data (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Metalhead: trainimgs\n",
    "using Images, ImageMagick\n",
    "\n",
    "function get_processed_data(args)\n",
    "    # Fetching the train and validation data and getting them into proper shape\t\n",
    "    X = trainimgs(CIFAR10)\n",
    "    imgs = [preprocess(X[i].img) for i in 1:40000]\n",
    "    #onehot encode labels of batch\n",
    "   \n",
    "    labels = onehotbatch([X[i].ground_truth.class for i in 1:40000],1:10)\n",
    "\n",
    "    train_pop = Int((1-args.splitr_)* 40000)\n",
    "    train = device.([(cat(imgs[i]..., dims = 4), labels[:,i]) for i in partition(1:train_pop, args.batchsize)])\n",
    "    valset = collect(train_pop+1:40000)\n",
    "    valX = cat(imgs[valset]..., dims = 4) |> device\n",
    "    valY = labels[:, valset] |> device\n",
    "\n",
    "    val = (valX,valY)\n",
    "    return train, val\n",
    "end\n",
    "\n",
    "function get_test_data()\n",
    "    # Fetch the test data from Metalhead and get it into proper shape.\n",
    "    test = valimgs(CIFAR10)\n",
    "\n",
    "    # CIFAR-10 does not specify a validation set so valimgs fetch the testdata instead of testimgs\n",
    "    testimgs = [preprocess(test[i].img) for i in 1:1000]\n",
    "    testY = onehotbatch([test[i].ground_truth.class for i in 1:1000], 1:10) |> device\n",
    "    testX = cat(testimgs..., dims = 4) |> device\n",
    "\n",
    "    test = (testX,testY)\n",
    "    return test\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Metalhead中提供的模型结构和预训练参数。\n",
    "\n",
    "Use the model structure and pre-training parameters provided in Metalhead.\n",
    "\n",
    "在源码中可以找到预训练权重的下载地址，例如[github](https://github.com/FluxML/Metalhead.jl/blob/fd4687a0f91a188f099a43d6464000162b20aa60/src/utils.jl)，我们从提供的[vgg19](https://github.com/FluxML/Metalhead.jl/releases/download/Models/vgg19.bson)下载地址中下载VGG19的权重文件，放在 deps 文件夹中。我的 deps 文件夹的路径是：\"~/.juliapro/JuliaPro_v1.4.1-1/packages/Metalhead/RZn9O/deps\"。\n",
    "\n",
    "The download address of the pre-training weights can be found in the source code, such as [github](https://github.com/FluxML/Metalhead.jl/blob/fd4687a0f91a188f099a43d6464000162b20aa60/src/utils.jl). We download the weight file of VGG19 from the provided [vgg19](https://github.com/FluxML/Metalhead.jl/releases/download/Models/vgg19.bson) download address and place it in the deps folder. The path of my deps folder is: \"~/.juliapro/JuliaPro_v1.4.1-1/packages/Metalhead/RZn9O/deps\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 3=>64, relu), BatchNorm(64), Conv((3, 3), 64=>64, relu), BatchNorm(64), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 64=>128, relu), BatchNorm(128), Conv((3, 3), 128=>128, relu), BatchNorm(128), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 128=>256, relu), BatchNorm(256), Conv((3, 3), 256=>256, relu), BatchNorm(256), Conv((3, 3), 256=>256, relu), BatchNorm(256), Conv((3, 3), 256=>256, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 256=>512, relu), BatchNorm(512), Conv((3, 3), 512=>512, relu), BatchNorm(512), Conv((3, 3), 512=>512, relu), BatchNorm(512), Conv((3, 3), 512=>512, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 512=>512, relu), BatchNorm(512), Conv((3, 3), 512=>512, relu), BatchNorm(512), Conv((3, 3), 512=>512, relu), BatchNorm(512), Conv((3, 3), 512=>512, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), flatten, Dense(512, 4096, relu), Dropout(0.5), Dense(4096, 4096, relu), Dropout(0.5), Dense(4096, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Metalhead\n",
    "\n",
    "function VGG19()\n",
    "    return Chain(\n",
    "            Conv((3, 3), 3 => 64, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(64),\n",
    "            Conv((3, 3), 64 => 64, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(64),\n",
    "            MaxPool((2,2)),\n",
    "            Conv((3, 3), 64 => 128, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(128),\n",
    "            Conv((3, 3), 128 => 128, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(128),\n",
    "            MaxPool((2,2)),\n",
    "            Conv((3, 3), 128 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(256),\n",
    "            Conv((3, 3), 256 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(256),\n",
    "            Conv((3, 3), 256 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(256),\n",
    "            Conv((3, 3), 256 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            MaxPool((2,2)),\n",
    "            Conv((3, 3), 256 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(512),\n",
    "            Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(512),\n",
    "            Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(512),\n",
    "            Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            MaxPool((2,2)),\n",
    "            Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(512),\n",
    "            Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(512),\n",
    "            Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            BatchNorm(512),\n",
    "            Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "            MaxPool((2,2)),\n",
    "            flatten,\n",
    "            Dense(512, 4096, relu),\n",
    "            Dropout(0.5),\n",
    "            Dense(4096, 4096, relu),\n",
    "            Dropout(0.5),\n",
    "            Dense(4096, 10))\n",
    "end\n",
    "model = VGG19() |> device\n",
    "\n",
    "# # Finetune MetalHead VGG19 without augmentation\n",
    "# vgg = VGG19()\n",
    "# model = Chain(vgg.layers[1:end-6],\n",
    "#               Dense(512, 4096, relu),\n",
    "#               Dropout(0.5),\n",
    "#               Dense(4096, 4096, relu),\n",
    "#               Dropout(0.5),\n",
    "#               Dense(4096, 10)) |> device\n",
    "\n",
    "# # Finetune MetalHead VGG19 with augmentation, images are resized to 224*224\n",
    "# vgg = VGG19()\n",
    "# model = Chain(vgg.layers[1:end-2],\n",
    "#               Dense(4096,10),\n",
    "#               softmax) |> device\n",
    "\n",
    "# # Finetune your trained models\n",
    "# function vgg19()\n",
    "#     ws = weights(\"vgg19.bson\")\n",
    "#     return Chain(\n",
    "#         Conv(ws[:conv1_1_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv1_1_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         Conv(ws[:conv1_2_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv1_2_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         MaxPool((2,2)),\n",
    "#         Conv(ws[:conv2_1_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv2_1_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         Conv(ws[:conv2_2_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv2_2_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         MaxPool((2,2)),\n",
    "#         Conv(ws[:conv3_1_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv3_1_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         Conv(ws[:conv3_2_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv3_2_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         Conv(ws[:conv3_3_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv3_3_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         Conv(ws[:conv3_4_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv3_4_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         MaxPool((2,2)),\n",
    "#         Conv(ws[:conv4_1_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv4_1_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         Conv(ws[:conv4_2_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv4_2_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         Conv(ws[:conv4_3_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv4_3_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         Conv(ws[:conv4_4_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv4_4_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         MaxPool((2,2)),\n",
    "#         Conv(ws[:conv5_1_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv5_1_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         Conv(ws[:conv5_2_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv5_2_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         Conv(ws[:conv5_3_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv5_3_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         Conv(ws[:conv5_4_w_0][end:-1:1,:,:,:][:,end:-1:1,:,:], ws[:conv5_4_b_0], relu, pad = (1,1), stride = (1,1), dilation = (1,1)),\n",
    "#         MaxPool((2,2)),\n",
    "#         x -> reshape(x, :, size(x, 4)),\n",
    "#         Dense(ws[:fc6_w_0]', ws[:fc6_b_0], relu),\n",
    "#         Dropout(0.5f0),\n",
    "#         Dense(ws[:fc7_w_0]', ws[:fc7_b_0], relu),\n",
    "#         Dropout(0.5f0),\n",
    "#         Dense(ws[:fc8_w_0]', ws[:fc8_b_0]),\n",
    "#         softmax)\n",
    "# end\n",
    "# model = vgg19() |> device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型并微调参数。\n",
    "\n",
    "Train the model and fine-tune the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(model; kws...)\n",
    "    # Initialize the hyperparameters\n",
    "    args = Args(; kws...)\n",
    "    \n",
    "    # Load the train, validation data \n",
    "    train, val = get_processed_data(args)\n",
    "\n",
    "    @info(\"Constructing Model\")\n",
    "    # Defining the loss and accuracy functions\n",
    "\n",
    "    loss(x, y) = logitcrossentropy(model(x), y)\n",
    "\n",
    "    ## Training\n",
    "    # Defining the callback and the optimizer\n",
    "    evalcb = throttle(() -> @show(loss(val...)), args.throttle)\n",
    "    opt = ADAM(args.lr)\n",
    "    @info(\"Training....\")\n",
    "    # Starting to train models\n",
    "    Flux.@epochs args.epochs Flux.train!(loss, params(model), train, opt, cb=evalcb)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要耐心等待几分钟，正在下载数据集和数据增广。\n",
    "\n",
    "Need to wait patiently for a few minutes, the dataset is being downloaded and image augmentation is in progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Constructing Model\n",
      "└ @ Main In[7]:8\n",
      "┌ Info: Training....\n",
      "└ @ Main In[7]:17\n",
      "┌ Info: Epoch 1\n",
      "└ @ Main /home/zhangzhi/.juliapro/JuliaPro_v1.4.1-1/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(val...) = 2.3033738f0\n",
      "loss(val...) = 1.6381592f0\n",
      "loss(val...) = 1.4765667f0\n",
      "loss(val...) = 1.5272578f0\n",
      "loss(val...) = 1.4042577f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main /home/zhangzhi/.juliapro/JuliaPro_v1.4.1-1/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(val...) = 1.2379736f0\n",
      "loss(val...) = 1.1534756f0\n",
      "loss(val...) = 1.1156354f0\n",
      "loss(val...) = 1.0893316f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main /home/zhangzhi/.juliapro/JuliaPro_v1.4.1-1/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(val...) = 1.2024394f0\n",
      "loss(val...) = 1.0005852f0\n",
      "loss(val...) = 0.9206779f0\n",
      "loss(val...) = 0.969336f0\n",
      "loss(val...) = 0.984805f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main /home/zhangzhi/.juliapro/JuliaPro_v1.4.1-1/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(val...) = 0.96014816f0\n",
      "loss(val...) = 0.9179143f0\n",
      "loss(val...) = 0.9446917f0\n",
      "loss(val...) = 1.1109371f0\n",
      "loss(val...) = 0.909474f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 5\n",
      "└ @ Main /home/zhangzhi/.juliapro/JuliaPro_v1.4.1-1/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(val...) = 0.8882381f0\n",
      "loss(val...) = 0.8820702f0\n",
      "loss(val...) = 0.8960527f0\n",
      "loss(val...) = 0.94824517f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 6\n",
      "└ @ Main /home/zhangzhi/.juliapro/JuliaPro_v1.4.1-1/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(val...) = 1.1659671f0\n",
      "loss(val...) = 0.94695526f0\n",
      "loss(val...) = 0.87784076f0\n",
      "loss(val...) = 0.87166667f0\n",
      "loss(val...) = 0.9482982f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 7\n",
      "└ @ Main /home/zhangzhi/.juliapro/JuliaPro_v1.4.1-1/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(val...) = 0.8773484f0\n",
      "loss(val...) = 1.0302075f0\n",
      "loss(val...) = 0.838604f0\n",
      "loss(val...) = 1.0184537f0\n",
      "loss(val...) = 0.8309129f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 8\n",
      "└ @ Main /home/zhangzhi/.juliapro/JuliaPro_v1.4.1-1/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(val...) = 0.8406193f0\n",
      "loss(val...) = 0.91691136f0\n",
      "loss(val...) = 1.0379539f0\n",
      "loss(val...) = 0.9353888f0\n",
      "loss(val...) = 0.9796433f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 9\n",
      "└ @ Main /home/zhangzhi/.juliapro/JuliaPro_v1.4.1-1/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(val...) = 0.91448677f0\n",
      "loss(val...) = 0.92203945f0\n",
      "loss(val...) = 0.82181627f0\n",
      "loss(val...) = 0.8147631f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 10\n",
      "└ @ Main /home/zhangzhi/.juliapro/JuliaPro_v1.4.1-1/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(val...) = 0.9315647f0\n",
      "loss(val...) = 0.88752526f0\n",
      "loss(val...) = 0.8546379f0\n",
      "loss(val...) = 0.90364754f0\n",
      "loss(val...) = 0.8723239f0\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型在测试集上的准确率.\n",
    "\n",
    "Test the accuracy of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x, y, m) = mean(onecold(cpu(m(x)), 1:10) .== onecold(cpu(y), 1:10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test(model)\n",
    "    test_data = get_test_data() |> device\n",
    "    # Print the final accuracy\n",
    "    @show(accuracy(test_data..., model))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(test_data..., model) = 0.747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.747"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Tracker\n",
    "using BSON: @load, @save\n",
    "\n",
    "pretrained = model |> cpu\n",
    "weights = Tracker.data.(params(pretrained))\n",
    "@save \"weights.bson\" weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load weights\n",
    "# weights = BSON.load(filename)\n",
    "# Flux.loadparams!(model, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
